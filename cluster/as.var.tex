\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{geometry}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\usepackage{amsfonts,amssymb,graphics,epsfig,verbatim,bm,latexsym,amsmath,url,amsbsy, amsthm}
\usepackage{enumitem}

\renewcommand{\qedsymbol}{$\blacksquare$}
\renewcommand{\qed}{\hfill\blacksquare}


\title{As. Variance Proof (sketch)}
\author{Juri Trifonov}
\date{\today}

\begin{document}

\maketitle

\subsection*{Proof of Theorem 3.1 under the perfect compliance and clusters}

Let us denote:

\[Q \equiv  \mathbb E [Y(1) - Y(0)],\]
\[H \equiv \mathbb E[N_g],\]
\[\hat{Q} \equiv \frac{1}{G} \sum_{g = 1}^{G} N_g \left[ \frac{A_g (\bar{Y}_g - \hat{\mu}(1, S_g, X_g, N_g))}{\hat{\pi}(S_g)} - \frac{(1 - A_g) (\bar{Y}_g - \hat{\mu}(0,S_g,X_g,N_g))}{1 - \hat{\pi}(S_g)}  + \hat{\mu}(1, S_g, X_g, N_g) - \hat{\mu}(0, S_g, X_g, N_g)\right],\]
\[\hat{H} \equiv \frac{1}{G} \sum_{g=1}^{G} N_g.\]

Then, we can write the estimator as follows:
\begin{align}
\sqrt{G}(\hat{\tau} - \tau) &= \sqrt{G} \left(\frac{\hat{Q}}{\hat{H}} - \frac{Q}{H}\right) \nonumber \\
&= \frac{1}{\hat{H}} \left[\sqrt{G}(\hat{Q} - Q)- \tau \sqrt{G}(\hat{H} - H)\right] \nonumber.
\end{align}

\subsubsection*{Step 1. Obtain the linear expansion of $\sqrt{G}(\hat{Q} - Q)$ and $\sqrt{G}(\hat{H} - H)$}
Consider $\sqrt{G}(\hat{Q} - Q)$:
\begin{align}
\sqrt{G}(\hat{Q} - Q) &= \sqrt{G}\Bigg\{\frac{1}{G} \sum_{g = 1}^{G} N_g \Bigg[ \frac{A_g (\bar{Y}_g - \hat{\mu}(1, S_g, X_g, N_g))}{\hat{\pi}(S_g)} - \frac{(1 - A_g) (\bar{Y}_g - \hat{\mu}(0,S_g,X_g,N_g))}{1 - \hat{\pi}(S_g)} \nonumber \\ 
&+ \hat{\mu}(1,S_g, X_g, N_g) - \hat{\mu}(0,S_g, X_g, N_g) \Bigg] - Q \Bigg\} \nonumber \\
&=\frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \left[\hat{\mu}(1, S_g, X_g, N_g) - \frac{A_g \hat{\mu}(1, S_g, X_g, N_g)}{\hat{\pi}(S_g)} \right] \nonumber \\
&+ \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \left[ \frac{(1-A_g) \hat{\mu}(0,S_g,X_g,N_g)}{1 - \hat{\pi}(S_g)} - \hat{\mu}(0,S_g,X_g,N_g) \right] \nonumber \\
&+ \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \frac{A_g \bar{Y}_g}{\hat{\pi}(S_g)} - \frac{1}{\sqrt{G}} \sum_{g = 1}^{G} N_g \frac{(1 - A_g) \bar{Y}_g}{1 - \hat{\pi}(S_g)} - \sqrt{G}Q \nonumber\\
&\equiv R_{n,1} + R_{n,2} + R_{n,3} \nonumber 
\end{align}

Applying Lemma P.1, we have that: 
 \begin{align}
 	&R_{n,1} = \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \left(1 - \frac{1}{\pi(S_g)}\right) A_g \tilde{\mu}(1, S_g, X_g, N_g) + \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g (1 - A_g) \tilde{\mu}(1, S_g, X_g, N_g) + o_p(1) \nonumber \\
 	&R_{n,2} = \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \left(\frac{1}{1 - \pi(S_g)} - 1\right) (1-A_g) \tilde{\mu}(0, S_g, X_g, N_g) + \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g A_g \tilde{\mu}(0, S_g, X_g, N_g) + o_p(1) \nonumber \\
 	&R_{n,3} = \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \frac{1}{\pi(S_g)} \tilde{\bar{Y}}_g(1) A_g - \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \frac{1 - A_g}{1 - \pi(S_g)} \tilde{\bar{Y}}_g(0) + \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g (\mathbb E [\bar{Y}_g(1) - \bar{Y}_g(0)|S_g] - \mathbb E [\bar{Y}_g(1) - \bar{Y}_g(0)]), \nonumber
 \end{align}
 where $\tilde{\bar{Y}}_g(a) = \bar{Y}_g(a) - \mathbb E[\bar{Y}_g(a) |S_g]$, for $a \in \{0,1\}$.
 
 Thus, it implies that:
 
 \begin{align}
 \sqrt{G}(\hat{Q} - Q)&= \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \left[ \left(1 - \frac{1}{\pi(S_g)}\right)\tilde{\mu}(1, S_g, X_g, N_g) - \hat{\mu}(0, S_g, X_g, N_g) + \frac{\tilde{\bar{Y}}_g(1)}{\pi(S_g)} \right]A_g \nonumber \\
 &+ \frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \left[ \left(\frac{1}{1-\pi(S_g)} -1\right)\tilde{\mu}(0, S_g, X_g, N_g) + \tilde{\mu}(1, S_g, X_g, N_g) - \frac{\tilde{\bar{Y}}_g(0)}{1-\pi(S_g)} \right](1-A_g) \nonumber \\
 &+ \left\{\frac{1}{\sqrt{G}} \sum_{g=1}^{G} N_g \left( \mathbb E [\bar{Y}_g(1) -\bar{Y}_g(0)|S_g] - \mathbb E[\bar{Y}_g(1) - \bar{Y}_g(0)] \right) \right\} + o_p \nonumber
 \end{align}

 Now let us consider $\sqrt{G}(\hat{H} - H)$. Note that we can rewrite it as
 \begin{align}
 	\sqrt{G}(\hat{H} - H)&=\sqrt{G}\left(\frac{1}{G} \sum_{g=1}^{G}N_g -\mathbb E[N_g]\right) \nonumber\\
 	&= \sqrt{G} \left( \frac{1}{G} \sum_{g=1}^{G}N_g A_g + \frac{1}{G} \sum_{g=1}^{G} N_g(1-A_g) - \mathbb E [N_g] \right) \nonumber
 \end{align}
 
 Now recall that $\sqrt{G}(\hat{\tau} - \tau) = \frac{1}{\hat{H}} \left[\sqrt{G}(\hat{Q} - Q)- \tau \sqrt{G}(\hat{H} - H)\right]$ and define $\mathcal D_g \equiv \{\bar{Y}_g(1),\bar{Y}_g(0),D_g,X_g, N_g\}$
 \begin{align}
 	&\Xi_1(\mathcal D_g,S_g) = N_g \left[ \left(1 - \frac{1}{\pi(S_g)}\right) \tilde{\mu}(1,S_g,X_g,N_g) - \tilde{\mu}(0,S_g,X_g,N_g) + \frac{\tilde{\bar{Y}}_g(1)}{\pi(S_g)}\right] - \tau N_g \nonumber \\
 	&\Xi_0(\mathcal D_g,S_g) = N_g \left[ \left(\frac{1}{1-\pi(S_g)} - 1\right) \tilde{\mu}(0,S_g,X_g,N_g) + \tilde{\mu}(1,S_g,X_g,N_g) - \frac{\tilde{\bar{Y}}_g(0)}{1-\pi(S_g)}\right] - \tau N_g \nonumber \\
 	&\Xi_2(\mathcal D_g,S_g) = N_g \left( \mathbb E[\bar{Y}_g(1) - \bar{Y}_g(0) |S_g] - \mathbb E[\bar{Y}_g(1) - \bar{Y}_g(0)] \right) + \tau \mathbb E[N_g] \nonumber .
 \end{align}
 
 Then, we can define the variance estimand as follows:
 \begin{align}
 \sqrt{G}(\hat{\tau} - \tau) = \frac{1}{\sum_{g=1}^G N_g} \left[ \frac{1}{\sqrt{G}} \sum_{g=1}^G \Xi_1(\mathcal D_g,S_g) A_g + \frac{1}{\sqrt{G}} \sum_{g=1}^G \Xi_0(\mathcal D_g, S_g) (1 - A_g) + \frac{1}{\sqrt{G}} \sum_{g=1}^G \Xi_2(\mathcal D_g, S_g) \right] \nonumber	
 \end{align}
\hfill $\qed$

\subsubsection*{Step 2. Obtain the asymptotic distribution of $\sqrt{G}(\hat{\tau} - \tau)$}
Applying Lemma P.2, we get that three terms are asymptotically normally distributed and independent from each other:

\begin{align}
	&\frac{1}{\sqrt{G}} \sum_{g=1}^{G} \Xi_1(\mathcal D_g, S_g) A_g \xrightarrow{\text{d}}N(0,\sigma_1^2) \nonumber \\
	&\frac{1}{\sqrt{G}} \sum_{g=1}^{G} \Xi_0(\mathcal D_g, S_g) (1-A_g) \xrightarrow{\text{d}}N(0,\sigma_0^2) \nonumber \\
	&\frac{1}{\sqrt{G}} \sum_{g=1}^{G} \Xi_2(\mathcal D_g, S_g) \xrightarrow{\text{d}}N(0,\sigma_0^2), \nonumber
\end{align}
where $\sigma_1^2 = \mathbb E[\pi(S_g) \Xi_1^2(\mathcal D_g, S_g)]$; $\sigma_0^2 = \mathbb E[(1-\pi(S_g)) \Xi_0^2(\mathcal D_g, S_g)]$ ; $\sigma_2^2 = \mathbb E[\Xi_2^2(\mathcal D_g, S_g)]$. Finally, we can state the asymptotic normality
\[\sqrt{G}(\hat{\tau} - \tau) \xrightarrow{\text{d}}N\left(0,\frac{\sigma^2_1 + \sigma_0^2 + \sigma_2^2}{\mathbb E[N_g]^2}\right), \sigma^2 = \frac{\sigma^2_1 + \sigma_0^2 + \sigma_2^2}{\mathbb E[N_g]^2}.\]
\hfill $\qed$

\subsubsection*{Step 3. Obtain a consistent estimator}
Following the results from (Jiang et all, 2023), we can define a consistent variance estimator as follows: 

\begin{align}
	\hat{\sigma}^2 = \frac{\frac{1}{G} \sum_{g=1}^G \left[A_g\hat{\Xi}_{1}^2(\mathcal D_g, S_g) + (1- A_g) \hat{\Xi}_{0}^2(\mathcal D_g, S_g) + \hat{\Xi}_2^2(\mathcal D_g, S_g) \right]}{(\frac{1}{G}\sum_{g=1}^G N_g)^2}, \nonumber
\end{align}
where 
\begin{align}
	&\hat{\Xi}_{1}(\mathcal D_g, s) = \tilde{\Xi}_{1}(s) - \frac{1}{G_1(s)} \sum_{j \in I_1(s)} \tilde{\Xi}_{1,j}(s) \nonumber, \\
	&\hat{\Xi}_{0}(\mathcal D_g, s) = \tilde{\Xi}_{0}(s) - \frac{1}{G_0(s)} \sum_{j \in I_0(s)} \tilde{\Xi}_{0,j}(s) \nonumber , \\
	& \hat{\Xi}_{2}(\mathcal D_g, s) = \left( \frac{1}{G_1(s)} \sum_{j \in I_1(s)} \left(N_j \bar{Y}_j + \hat{\tau}  N_j \right) \right) - \left( \frac{1}{G_0(s)} \sum_{j \in I_0 (s)} \left(N_j \bar{Y}_j + \hat{\tau} N_j \right) \right), \nonumber \\
	& \hat{\Xi}_{2}(\mathcal D_g, s) = \left( \frac{1}{G_1(s)} \sum_{j \in I_1(s)} N_j \bar{Y}_j  -  \frac{1}{G_0(s)} \sum_{j \in I_0 (s)} N_j \bar{Y}_j \right) + \hat{\tau} \frac{1}{G} \sum_{g=1}^G N_g, \nonumber \\
	&\tilde{\Xi}_{1}(\mathcal D_g, s) = \left(1 - \frac{1}{\hat{\pi}(s)} \right)N_g\hat{\mu}(1,s,X_g,N_g) - N_g\hat{\mu}(0,s,X_g,N_g) + N_g\frac{\bar{Y}_g}{\hat{\pi}(s)} - \hat{\tau} N_g, \nonumber \\
	& \tilde{\Xi}_{0}(\mathcal D_g, s) = \left(\frac{1}{1 - \hat{\pi}(s)} - 1 \right)N_g\hat{\mu}(0,s,X_g,N_g) + N_g\hat{\mu}(1,s,X_g,N_g) - N_g\frac{\bar{Y}_g}{1-\hat{\pi}(s)} - \hat{\tau} N_g. \nonumber
\end{align}
\hfill $\qed$
\end{document}

~/Desktop/pkg.sreg/sreg.func_v.4.6.R